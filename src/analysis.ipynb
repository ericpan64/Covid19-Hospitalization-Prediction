{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitd1c8c3e02a4349d4a7a5beac44c97aaa",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Data Inspection\n",
    "- Goal: understand quantity and sparsity of data across patients"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Global Consts\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from etl import load_csvs_to_dataframe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1251 3161\n",
      "         person_id  concept_id\n",
      "0              909      380378\n",
      "1             1196       75909\n",
      "2              156      438409\n",
      "3             1064      435875\n",
      "4              925       80502\n",
      "...            ...         ...\n",
      "1590019          2       32209\n",
      "1590020        424       32209\n",
      "1590021        168       32209\n",
      "1590022       1198       32209\n",
      "1590023        489       32209\n",
      "\n",
      "[1590024 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "fn_to_df_map = load_csvs_to_dataframe_dict()\n",
    "\n",
    "# Get # of unique instances per concept_id\n",
    "## get \"good enough\" largest df size\n",
    "person_count = len(fn_to_df_map['person.csv']['person_id'])\n",
    "clin_concept_count = 0\n",
    "## for each csv with clinical concepts, get unique counts\n",
    "for fn in FILENAME_CLIN_CONCEPT_MAP:\n",
    "    df = fn_to_df_map[fn]\n",
    "    for col in FILENAME_CLIN_CONCEPT_MAP[fn]:\n",
    "        clin_concept_count += len(df[col].unique())\n",
    "\n",
    "## assume worst case that each person has once occurrence of every possible clinical concept\n",
    "print(person_count, clin_concept_count) # 1251 person_ids * 3161 unique concepts = 3,954,411 max num of rows\n",
    "\n",
    "## init empty dataframe df_all\n",
    "idx = range(person_count * clin_concept_count)\n",
    "cols = ['person_id', 'concept_id']\n",
    "df_all = pd.DataFrame(index=idx, columns=cols)\n",
    "## populate df_all (unique person_id per concept_id)\n",
    "count = 0\n",
    "for fn in FILENAME_CLIN_CONCEPT_MAP:\n",
    "    df = fn_to_df_map[fn]\n",
    "    for col in FILENAME_CLIN_CONCEPT_MAP[fn]:\n",
    "        # pre-process: get all non-unique (person_id, concept_id) pairs\n",
    "        df_sliced = df.loc[:, ['person_id', col]]\n",
    "        df_sliced = df_sliced.dropna()\n",
    "        df_sliced = df_sliced.rename(columns={col: 'concept_id'})\n",
    "        ## set appropriate index\n",
    "        n_rows = len(df_sliced)\n",
    "        idx = pd.Series(range(count, count+n_rows))\n",
    "        df_sliced = df_sliced.set_index(idx) \n",
    "\n",
    "        # append to df_all\n",
    "        df_all.iloc[idx, :] = df_sliced\n",
    "        count += n_rows\n",
    "\n",
    "## remove NaN\n",
    "df_all = df_all.dropna().astype('int')\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                 concept_name  ...  unique_pid_count\nconcept_id                                                     ...                  \n44814724                                                  NaN  ...              1251\n4033240                                                   NaN  ...              1251\n44818518                                                  NaN  ...              1251\n32019                                                     NaN  ...              1251\n44818702                                                  NaN  ...              1251\n...                                                       ...  ...               ...\n2788037      Respiratory Ventilation, 24-96 Consecutive Hours  ...                 1\n2784252     Detachment at Right Lower Leg, High, Open Appr...  ...                 1\n2784255     Detachment at Left Lower Leg, High, Open Approach  ...                 1\n2784265     Detachment at Right Foot, Partial 2nd Ray, Ope...  ...                 1\n2724536                   Release Lumbar Nerve, Open Approach  ...                 1\n\n[2376 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get count of unique person_id per concept_id\n",
    "df_all_summary = df_all.drop_duplicates(keep='first')\\\n",
    "    .groupby(['concept_id'])\\\n",
    "    .agg({'person_id': 'count'})\\\n",
    "    .rename(columns={'person_id': 'unique_pid_count'})\\\n",
    "    .sort_values('unique_pid_count', ascending=False)\n",
    "\n",
    "## add concept_name, table labels from data_dict\n",
    "### names\n",
    "concept_ids = df_all_summary.reset_index().loc[:, 'concept_id']\n",
    "cid_to_name = lambda cid: CONCEPT_ID_TO_NAME_MAP[cid] if cid in CONCEPT_ID_TO_NAME_MAP else pd.NA\n",
    "concept_names = concept_ids.apply(cid_to_name).rename('concept_name')\n",
    "concept_ids_with_names = pd.concat([concept_ids, concept_names], axis=1).set_index('concept_id')\n",
    "df_all_summary.insert(0, \"concept_name\", concept_ids_with_names)\n",
    "\n",
    "### table\n",
    "cid_to_table = lambda cid: CONCEPT_ID_TO_TABLE_MAP[cid] if cid in CONCEPT_ID_TO_TABLE_MAP else pd.NA\n",
    "concept_table = concept_ids.apply(cid_to_table).rename('from_table')\n",
    "concept_ids_with_table = pd.concat([concept_ids, concept_table], axis=1).set_index('concept_id')\n",
    "df_all_summary.insert(1, \"from_table\", concept_ids_with_table)\n",
    "\n",
    "\n",
    "# Get count of average # of occurrences per person with the given concept_id\n",
    "m = len(df_all)\n",
    "df_ones = pd.DataFrame(np.ones((m, 1)))\n",
    "df_all_w_ones = pd.concat([df_all, df_ones], axis=1)\n",
    "df_all_avg = df_all_w_ones.groupby(['concept_id', 'person_id'])\\\n",
    "    .agg(['sum'])\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={0: 'avg_per_pid'})\\\n",
    "    .groupby(['concept_id'])\\\n",
    "    .agg(['mean'])\n",
    "\n",
    "## clean-up formatting a bit\n",
    "df_all_avg.columns.droplevel([1,2]) # remove multiindex\n",
    "df_all_avg = df_all_avg.loc[:, 'avg_per_pid'] # keep only avg_per_pid\n",
    "\n",
    "## add to df_all_summary\n",
    "df_all_summary.insert(1, \"avg_per_pid\", df_all_avg)\n",
    "\n",
    "\n",
    "# Save to csv\n",
    "df_all_summary.to_csv(DATA_PATH + '/concept_summary.csv')\n",
    "\n",
    "print(df_all_summary)"
   ]
  },
  {
   "source": [
    "## Clustering Analysis - Finding Highest-Separation Feature Combinations\n",
    "- Goal: find set of features that result in best PCA Clustering\n",
    "- Pipeline: pick set of features (profile) -> run PCA -> manually view data -> run K-Means/GMM to cluster -> score clusters: use this as predictive measurement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}