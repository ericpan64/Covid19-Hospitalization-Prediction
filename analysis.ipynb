{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitd1c8c3e02a4349d4a7a5beac44c97aaa",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Data Inspection\n",
    "- Goal: understand quantity and sparsity of data across patients"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Global Consts\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "DATA_PATH = os.getcwd() + '/data/DREAM_data/q2_synthetic_data_08-19-2020'\n",
    "TRAIN_PATH = DATA_PATH + '/training'\n",
    "EVAL_PATH = DATA_PATH + '/evaluation'\n",
    "FILENAME_LIST = ['condition_occurrence.csv', 'device_exposure.csv', 'goldstandard.csv', \n",
    "    'measurement.csv', 'observation_period.csv', 'observation.csv', \n",
    "    'person.csv', 'procedure_occurrence.csv', 'visit_occurrence.csv']\n",
    "FILENAME_CLIN_CONCEPT_MAP = { # maps str->list(str)\n",
    "    'condition_occurrence.csv': ['condition_concept_id',\n",
    "                                'condition_type_concept_id',\n",
    "                                'condition_source_concept_id',\n",
    "                                'condition_status_concept_id'],\n",
    "    'device_exposure.csv': ['device_concept_id',\n",
    "                            'device_type_concept_id',\n",
    "                            'device_source_concept_id'],\n",
    "    'measurement.csv': ['measurement_concept_id',\n",
    "                        'measurement_type_concept_id',\n",
    "                        'operator_concept_id',\n",
    "                        'value_as_concept_id',\n",
    "                        'unit_concept_id',\n",
    "                        'measurement_source_concept_id'],\n",
    "    'observation.csv': ['observation_concept_id',\n",
    "                        'observation_type_concept_id',\n",
    "                        'value_as_concept_id',\n",
    "                        'qualifier_concept_id',\n",
    "                        'unit_concept_id',\n",
    "                        'observation_source_concept_id'],\n",
    "    'observation_period.csv': ['period_type_concept_id'],\n",
    "    'procedure_occurrence.csv': ['procedure_concept_id',\n",
    "                                'procedure_type_concept_id',\n",
    "                                'modifier_concept_id',\n",
    "                                'procedure_source_concept_id'],\n",
    "    'visit_occurrence.csv': ['visit_concept_id',\n",
    "                        'visit_type_concept_id',\n",
    "                        'visit_source_concept_id',\n",
    "                        'admitting_source_concept_id',\n",
    "                        'discharge_to_concept_id']\n",
    "}\n",
    "DATA_DICT_DF = pd.read_csv(DATA_PATH + '/data_dictionary.csv').loc[:, ['concept_id', 'concept_name', 'table']]\n",
    "CONCEPT_ID_TO_NAME_MAP = DATA_DICT_DF.loc[:, ['concept_id', 'concept_name']].set_index('concept_id').to_dict()['concept_name']\n",
    "CONCEPT_ID_TO_TABLE_MAP = DATA_DICT_DF.loc[:, ['concept_id', 'table']].set_index('concept_id').to_dict()['table']\n",
    "\n",
    "# Load datasets\n",
    "def load_all_to_dataframe(fn_list=FILENAME_LIST, path=TRAIN_PATH):\n",
    "    \"\"\"\n",
    "    :returns: dict (str->DataFrame)\n",
    "    \"\"\"\n",
    "    fn_to_df_dict = {}\n",
    "    for fn in fn_list:\n",
    "        df = pd.read_csv(path + '/' + fn)\n",
    "        fn_to_df_dict[fn] = df\n",
    "    return fn_to_df_dict\n",
    "\n",
    "# Use map to quickly access copy of df\n",
    "fn_to_df_map = load_all_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1251 3161\n",
      "         person_id  concept_id\n",
      "0              909      380378\n",
      "1             1196       75909\n",
      "2              156      438409\n",
      "3             1064      435875\n",
      "4              925       80502\n",
      "...            ...         ...\n",
      "1590019          2       32209\n",
      "1590020        424       32209\n",
      "1590021        168       32209\n",
      "1590022       1198       32209\n",
      "1590023        489       32209\n",
      "\n",
      "[1590024 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get # of unique instances per concept_id\n",
    "## get \"good enough\" largest df size\n",
    "person_count = len(fn_to_df_map['person.csv']['person_id'])\n",
    "clin_concept_count = 0\n",
    "## for each csv with clinical concepts, get unique counts\n",
    "for fn in FILENAME_CLIN_CONCEPT_MAP:\n",
    "    df = fn_to_df_map[fn]\n",
    "    for col in FILENAME_CLIN_CONCEPT_MAP[fn]:\n",
    "        clin_concept_count += len(df[col].unique())\n",
    "\n",
    "## assume worst case that each person has once occurrence of every possible clinical concept\n",
    "print(person_count, clin_concept_count) # 1251 person_ids * 3161 unique concepts = 3,954,411 max num of rows\n",
    "\n",
    "## init empty dataframe df_all\n",
    "idx = range(person_count * clin_concept_count)\n",
    "cols = ['person_id', 'concept_id']\n",
    "df_all = pd.DataFrame(index=idx, columns=cols)\n",
    "## populate df_all (unique person_id per concept_id)\n",
    "count = 0\n",
    "for fn in FILENAME_CLIN_CONCEPT_MAP:\n",
    "    df = fn_to_df_map[fn]\n",
    "    for col in FILENAME_CLIN_CONCEPT_MAP[fn]:\n",
    "        # pre-process: get all non-unique (person_id, concept_id) pairs\n",
    "        df_sliced = df.loc[:, ['person_id', col]]\n",
    "        df_sliced = df_sliced.dropna()\n",
    "        df_sliced = df_sliced.rename(columns={col: 'concept_id'})\n",
    "        ## set appropriate index\n",
    "        n_rows = len(df_sliced)\n",
    "        idx = pd.Series(range(count, count+n_rows))\n",
    "        df_sliced = df_sliced.set_index(idx) \n",
    "\n",
    "        # append to df_all\n",
    "        df_all.iloc[idx, :] = df_sliced\n",
    "        count += n_rows\n",
    "\n",
    "## remove NaN\n",
    "df_all = df_all.dropna().astype('int')\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                 concept_name  avg_per_pid  \\\nconcept_id                                                                   \n44814724                                                  NaN     1.000000   \n4033240                                                   NaN    42.247002   \n44818518                                                  NaN    33.984812   \n32019                                                     NaN    30.432454   \n44818702                                                  NaN   144.921663   \n...                                                       ...          ...   \n2788037      Respiratory Ventilation, 24-96 Consecutive Hours     2.000000   \n2784252     Detachment at Right Lower Leg, High, Open Appr...     2.000000   \n2784255     Detachment at Left Lower Leg, High, Open Approach     2.000000   \n2784265     Detachment at Right Foot, Partial 2nd Ray, Ope...     2.000000   \n2724536                   Release Lumbar Nerve, Open Approach     2.000000   \n\n                      from_table  unique_pid_count  \nconcept_id                                          \n44814724                     NaN              1251  \n4033240                      NaN              1251  \n44818518                     NaN              1251  \n32019                        NaN              1251  \n44818702                     NaN              1251  \n...                          ...               ...  \n2788037     procedure_occurrence                 1  \n2784252     procedure_occurrence                 1  \n2784255     procedure_occurrence                 1  \n2784265     procedure_occurrence                 1  \n2724536     procedure_occurrence                 1  \n\n[2376 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get count of unique person_id per concept_id\n",
    "df_all_summary = df_all.drop_duplicates(keep='first')\\\n",
    "    .groupby(['concept_id'])\\\n",
    "    .agg({'person_id': 'count'})\\\n",
    "    .rename(columns={'person_id': 'unique_pid_count'})\\\n",
    "    .sort_values('unique_pid_count', ascending=False)\n",
    "\n",
    "## add concept_name, table labels from data_dict\n",
    "### names\n",
    "concept_ids = df_all_summary.reset_index().loc[:, 'concept_id']\n",
    "cid_to_name = lambda cid: CONCEPT_ID_TO_NAME_MAP[cid] if cid in CONCEPT_ID_TO_NAME_MAP else pd.NA\n",
    "concept_names = concept_ids.apply(cid_to_name).rename('concept_name')\n",
    "concept_ids_with_names = pd.concat([concept_ids, concept_names], axis=1).set_index('concept_id')\n",
    "df_all_summary.insert(0, \"concept_name\", concept_ids_with_names)\n",
    "\n",
    "### table\n",
    "cid_to_table = lambda cid: CONCEPT_ID_TO_TABLE_MAP[cid] if cid in CONCEPT_ID_TO_TABLE_MAP else pd.NA\n",
    "concept_table = concept_ids.apply(cid_to_table).rename('from_table')\n",
    "concept_ids_with_table = pd.concat([concept_ids, concept_table], axis=1).set_index('concept_id')\n",
    "df_all_summary.insert(1, \"from_table\", concept_ids_with_table)\n",
    "\n",
    "\n",
    "# Get count of average # of occurrences per person with the given concept_id\n",
    "m = len(df_all)\n",
    "df_ones = pd.DataFrame(np.ones((m, 1)))\n",
    "df_all_w_ones = pd.concat([df_all, df_ones], axis=1)\n",
    "df_all_avg = df_all_w_ones.groupby(['concept_id', 'person_id'])\\\n",
    "    .agg(['sum'])\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={0: 'avg_per_pid'})\\\n",
    "    .groupby(['concept_id'])\\\n",
    "    .agg(['mean'])\n",
    "\n",
    "## clean-up formatting a bit\n",
    "df_all_avg.columns.droplevel([1,2]) # remove multiindex\n",
    "df_all_avg = df_all_avg.loc[:, 'avg_per_pid'] # keep only avg_per_pid\n",
    "\n",
    "## add to df_all_summary\n",
    "df_all_summary.insert(1, \"avg_per_pid\", df_all_avg)\n",
    "\n",
    "\n",
    "# Save to csv\n",
    "df_all_summary.to_csv(DATA_PATH + '/concept_summary.csv')\n",
    "\n",
    "print(df_all_summary)"
   ]
  },
  {
   "source": [
    "## Clustering Analysis - Finding Highest-Separation Feature Combinations\n",
    "- Goal: find set of features that result in best PCA Clustering\n",
    "- Pipeline: pick set of features (profile) -> run PCA -> manually view data -> run K-Means/GMM to cluster -> score clusters: use this as predictive measurement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}